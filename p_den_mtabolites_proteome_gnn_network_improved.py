# -*- coding: utf-8 -*-
"""P den_Mtabolites_Proteome_GNN network_improved.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XWgnIenzkSlAB9EpnEYk7mD1ZDmdG7wG
"""

!pip install torch-geometric torch-scatter torch-sparse openpyxl --quiet

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from torch_geometric.data import Data
from torch_geometric.nn import GATConv
from torch_geometric.utils import add_self_loops, dropout_edge
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files

uploaded = files.upload()
metab_06 = pd.read_excel("OD_0.6_Metabolomics_2.xlsx")
proteo_06 = pd.read_excel("OD_0.6_Proteomics_1.xlsx")
metab_2 = pd.read_excel("OD_2_Metabolomics_2.xlsx")

def clean_text(text):
    if pd.isna(text):
        return ""
    return text.lower().replace('â†’', '->').replace('â†”', '<->')

metab_06['clean_reaction'] = metab_06['Reaction Name'].apply(clean_text)
metab_06['clean_pathway'] = metab_06['Known Pathway'].apply(clean_text)
proteo_06['clean_reaction'] = proteo_06['Reaction Name'].apply(clean_text)
proteo_06['clean_pathway'] = proteo_06['Known Pathway'].apply(clean_text)

# -------------------------------
# ðŸ”— Build Graph Edges
# -------------------------------
inferred_edges = []
for _, mrow in metab_06.iterrows():
    mname = mrow['Metabolite_ID'].lower()
    mpath = mrow['clean_pathway']
    for _, prow in proteo_06.iterrows():
        pname = prow['Protein name'].lower()
        preact = prow['clean_reaction']
        ppath = prow['clean_pathway']
        if (mname in preact) or (mname in ppath) or (mpath and mpath in ppath):
            inferred_edges.append((mrow['Metabolite_ID'], prow['Protein name']))

met_nodes = metab_06['Metabolite_ID'].unique().tolist()
prot_nodes = proteo_06['Protein name'].unique().tolist()
connected_proteins = set([p for _, p in inferred_edges])
filtered_prot_nodes = [p for p in prot_nodes if p in connected_proteins]
all_nodes = met_nodes + filtered_prot_nodes
node_to_idx = {name: i for i, name in enumerate(all_nodes)}

edge_index, _ = add_self_loops(
    torch.tensor([[node_to_idx[m], node_to_idx[p]] for m, p in inferred_edges], dtype=torch.long).t().contiguous(),
    num_nodes=len(all_nodes)
)

# -------------------------------
# ðŸ§¬ Build Node Features
# -------------------------------
metab_all = pd.concat([
    metab_06[['Metabolite_ID', 'WT1', 'WT2', 'WT3']].rename(columns={'WT1': 'S1', 'WT2': 'S2', 'WT3': 'S3'}),
    metab_06[['Metabolite_ID', 'HNOX1', 'HNOX2', 'HNOX3']].rename(columns={'HNOX1': 'S1', 'HNOX2': 'S2', 'HNOX3': 'S3'})
])
metab_all = metab_all.groupby('Metabolite_ID').mean().reset_index()

scaler = MinMaxScaler()
metab_expr = scaler.fit_transform(metab_all[['S1', 'S2', 'S3']].values)

protein_go_cols = [col for col in proteo_06.columns if col.startswith("GO_Embedding")]
go_features = proteo_06.set_index('Protein name').loc[filtered_prot_nodes][protein_go_cols].values.astype(np.float32)

x = np.random.normal(0, 0.01, size=(len(all_nodes), metab_expr.shape[1] + go_features.shape[1])).astype(np.float32)
for i, m in enumerate(met_nodes):
    x[node_to_idx[m], :metab_expr.shape[1]] = metab_expr[i]
for i, p in enumerate(filtered_prot_nodes):
    x[node_to_idx[p], metab_expr.shape[1]:] = go_features[i]

node_type = np.array([1]*len(met_nodes) + [0]*len(filtered_prot_nodes)).reshape(-1, 1)
x = np.hstack([x, node_type])
x_tensor = torch.tensor(np.nan_to_num(x), dtype=torch.float)

# -------------------------------
# ðŸŽ¯ Labels
# -------------------------------
y_raw_wt = proteo_06.set_index('Protein name').loc[filtered_prot_nodes][['WT1', 'WT2', 'WT3']].mean(axis=1)
output_scaler = StandardScaler()
y_scaled_wt = output_scaler.fit_transform(y_raw_wt.values.reshape(-1, 1)).flatten()

train_mask = torch.zeros(len(all_nodes), dtype=torch.bool)
for p in filtered_prot_nodes:
    train_mask[node_to_idx[p]] = True

y_tensor = torch.zeros(len(all_nodes), dtype=torch.float)
for i, p in enumerate(filtered_prot_nodes):
    y_tensor[node_to_idx[p]] = y_scaled_wt[i]

data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor, train_mask=train_mask)

# -------------------------------
# ðŸ”® Define GAT model
# -------------------------------
class GATEnhancedModel(nn.Module):
    def __init__(self, input_dim, hidden_dim=128, heads=4):
        super(GATEnhancedModel, self).__init__()
        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)
        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)
        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, concat=True)
        self.bn2 = nn.BatchNorm1d(hidden_dim * heads)
        self.out_lin = nn.Linear(hidden_dim * heads, 1)

    def forward(self, x, edge_index):
        x = self.gat1(x, edge_index)
        x = self.bn1(x)
        x = F.elu(x)
        x = F.dropout(x, p=0.3, training=self.training)
        x = self.gat2(x, edge_index)
        x = self.bn2(x)
        x = F.elu(x)
        x = F.dropout(x, p=0.3, training=self.training)
        return self.out_lin(x).view(-1)

# -------------------------------
# ðŸš€ Train
# -------------------------------
model = GATEnhancedModel(input_dim=data.x.shape[1])
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)

for epoch in range(300):
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = F.mse_loss(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    scheduler.step()
    if epoch % 50 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# -------------------------------
# ðŸ“ˆ Evaluate OD=0.6
# -------------------------------
model.eval()
predicted = model(data.x, data.edge_index).detach().numpy()
actual = data.y.numpy()
protein_indices = [node_to_idx[p] for p in filtered_prot_nodes]
predicted_unscaled = output_scaler.inverse_transform(predicted[protein_indices].reshape(-1, 1)).flatten()
actual_unscaled = output_scaler.inverse_transform(actual[protein_indices].reshape(-1, 1)).flatten()

plt.figure(figsize=(6, 6))
sns.scatterplot(x=actual_unscaled, y=predicted_unscaled, alpha=0.7)
plt.xlabel("Actual Protein Expression (Unscaled)")
plt.ylabel("Predicted Protein Expression (Unscaled)")
plt.title("GAT Model: Predicted vs Actual Protein Expression (OD=0.6)")
plt.grid(True)
plt.plot([actual_unscaled.min(), actual_unscaled.max()],
         [actual_unscaled.min(), actual_unscaled.max()], 'r--')
plt.show()

# Predict OD=2
wt_x_od2 = np.zeros((len(all_nodes), x_tensor.shape[1]), dtype=np.float32)
hnox_x_od2 = np.zeros((len(all_nodes), x_tensor.shape[1]), dtype=np.float32)

print("Available columns in metab_2:", metab_2.columns.tolist())
# Attempt to reset index if Metabolite_ID is already the index
if 'Metabolite_ID' not in metab_2.columns and metab_2.index.name == 'Metabolite_ID':
    metab_2.reset_index(inplace=True)

if 'Metabolite_ID' in metab_2.columns:
    metab_2 = metab_2.set_index('Metabolite_ID')
else:
    raise ValueError("Column 'Metabolite_ID' not found in OD_2_Metabolomics.xlsx")

for m in met_nodes:
    if m in metab_2.index:
        try:
            wt_vals = metab_2.loc[m, ['WT1', 'WT2', 'WT3']].values.reshape(1, -1)
            hnox_vals = metab_2.loc[m, ['HNOX1', 'HNOX2', 'HNOX3']].values.reshape(1, -1)
            wt_scaled_vals = scaler.transform(wt_vals)[0]
            hnox_scaled_vals = scaler.transform(hnox_vals)[0]
            wt_x_od2[node_to_idx[m], :3] = wt_scaled_vals
            hnox_x_od2[node_to_idx[m], :3] = hnox_scaled_vals
        except:
            continue

wt_pred = model(torch.tensor(wt_x_od2, dtype=torch.float), data.edge_index).detach().numpy()[protein_indices]
hnox_pred = model(torch.tensor(hnox_x_od2, dtype=torch.float), data.edge_index).detach().numpy()[protein_indices]

wt_pred_unscaled = output_scaler.inverse_transform(wt_pred.reshape(-1, 1)).flatten()
hnox_pred_unscaled = output_scaler.inverse_transform(hnox_pred.reshape(-1, 1)).flatten()

pred_table = pd.DataFrame({
    "Protein": filtered_prot_nodes,
    "Predicted_OD2_WT": wt_pred_unscaled,
    "Predicted_OD2_HNOX": hnox_pred_unscaled
})
pred_table.to_csv("Predicted_Proteins_OD2_WT_HNOX_1.csv", index=False)
#print("Prediction results saved to Predicted_Proteins_OD2_WT_HNOX_1.csv")